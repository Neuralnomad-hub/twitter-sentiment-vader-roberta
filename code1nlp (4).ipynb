{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "VADER-Based Sentiment Analysis on Tweets V/S Roberta based transformer from hugging face for sentiment analysis using NLP\n",
        "\n"
      ],
      "metadata": {
        "id": "VqcdIq9w2lbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.first we are going to start with VADER-Based sentiment analysis"
      ],
      "metadata": {
        "id": "xdcFFmHx2pTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlEeihIa2jWf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"twitter_data_500.csv\", header=None, names=[\"textID\", \"text\"])\n",
        "print(df.iloc[3:])"
      ],
      "metadata": {
        "id": "QX5gTr2D2wOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"vader_lexicon\")"
      ],
      "metadata": {
        "id": "0hbn-ZTj2zSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize VADER sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Analyze each tweet and store results\n",
        "results = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = row['text']\n",
        "    myid = row['textID']\n",
        "    if isinstance(text, str):\n",
        "        results[myid] = sia.polarity_scores(text)\n",
        "    else:\n",
        "        results[myid] = {\"neg\": 0, \"neu\": 0, \"pos\": 0, \"compound\": 0}"
      ],
      "metadata": {
        "id": "2NC7Mh7m23mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the results to DataFrame\n",
        "vader = pd.DataFrame(results).T\n",
        "vader = vader.reset_index().rename(columns={\"index\": \"textID\"})\n",
        "vader = vader.merge(df, on=\"textID\", how=\"left\")\n",
        "\n",
        "# Labeling sentiment based on compound score\n",
        "vader['Label'] = vader['compound'].apply(lambda c: 'positive' if c >= 0.05 else ('negative' if c <= -0.05 else 'neutral'))\n",
        "output=vader.drop('textID', axis=1)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "4dX2165r28Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize sentiment distribution\n",
        "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
        "sns.barplot(data=vader, x=\"Label\", y=\"pos\", ax=axs[0])\n",
        "sns.barplot(data=vader, x=\"Label\", y=\"neu\", ax=axs[1])\n",
        "sns.barplot(data=vader, x=\"Label\", y=\"neg\", ax=axs[2])\n",
        "\n",
        "axs[0].set_title(\"Positive\")\n",
        "axs[1].set_title(\"Neutral\")\n",
        "axs[2].set_title(\"Negative\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rRyjNz8r2--2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2.Now we gonna use Robverta Based transformer from Huggingface"
      ],
      "metadata": {
        "id": "DSrO8W8P3G_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#roberta based tweet sentiment analysis\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "_YCqQ9vn3ChH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "df1 = pd.read_csv(\"twitter_data_500.csv\", header=None)\n",
        "df1.columns = ['textID', 'text']\n",
        "def polarity_scores_roberta(texts):\n",
        "    neg = []\n",
        "    neu = []\n",
        "    pos = []\n",
        "    for text in texts:\n",
        "        if not isinstance(text, str) or text.strip() == \"\":\n",
        "            neg.append(0)\n",
        "            neu.append(0)\n",
        "            pos.append(0)\n",
        "            continue\n",
        "        encoded = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        with torch.no_grad():\n",
        "            output = model(**encoded)\n",
        "        scores = output.logits[0].numpy()\n",
        "        scores = softmax(scores)\n",
        "        neg.append(scores[0])\n",
        "        neu.append(scores[1])\n",
        "        pos.append(scores[2])\n",
        "    return neg, neu, pos\n",
        "neg, neu, pos = polarity_scores_roberta(df1[\"text\"].tolist())\n",
        "df1['roberta_neg'] = neg\n",
        "df1['roberta_neu'] = neu\n",
        "df1['roberta_pos'] = pos\n",
        "# Display results, excluding the 'text' column\n",
        "display(df1.drop('text', axis=1).head(10))"
      ],
      "metadata": {
        "id": "4iubv41n3MZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}